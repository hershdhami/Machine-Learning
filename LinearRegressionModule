import torch
from torch import nn
import matplotlib.pyplot as plt

torch.__version__

weight = 0.7
bias = 0.3

start = 0
end = 1
step = 0.02

X = torch.arange(start, end, step).unsqueeze(dim=1)
y = weight * X + bias

X[:10], y[:10]

train_split = int(0.8 * len(X))
X_train, y_train = X[:train_split], y[:train_split]
X_test, y_test = X[train_split:], y[train_split:]

class LinearRegressionModelV2(nn.Module):
    def __init__(self):
      super().__init__()

      #Use nn.Linear() for creating the model parameters
      self.linear_layer = nn.Linear(in_features=1,out_features=1)

      #Have to define what the input and output is of the function
    def forward(self, x: torch.Tensor) -> torch.Tensor:
      return self.linear_layer(x)


torch.manual_seed(42)
model_1 = LinearRegressionModelV2()
model_1, model_1.state_dict()

loss_fn = nn.L1Loss()

optimizer = torch.optim.SGD(params=model_1.parameters(),
                            lr=0.01)

epochs = 100
train_loss_values = []
test_loss_values = []

for epoch in range(epochs):
  model_1.train()

  y_preds = model_1(X_train)

  loss = loss_fn(y_preds, y_train)

  optimizer.zero_grad()

  loss.backward()

  optimizer.step()

  model_1.eval()

  with torch.inference_mode():
    test_pred = model_1(X_test)

    #Remember because we are going to convert loss into array we need to convert it to float
    loss = loss_fn(test_pred, y_test.type(torch.float))

    if epoch % 10 == 0: 
      train_loss_values.append(loss.detach().numpy())
      test_loss_values.append(loss.detach().numpy())

print(f"The new values of the weight and bias are ")
print(model_1.state_dict())
print(f"The actual weight is { weight } and the bias is { bias }") 
